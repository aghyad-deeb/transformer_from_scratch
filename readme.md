# Transformer Implementation

Building a transformer using only pytorch documentation and Vaswani et al., 
2017 as reference (no tutorials were followed. Eddits from memory made to make
it a GPT).

jaxtyping was used to maintain tensor dimensions. All layers implemented from 
basic pytorch functions (no einops).

## Milestones

- [x] Build the architecture
- [x] Implement the training loop
- [x] Train a simple network
- [ ] Create an MLX version

