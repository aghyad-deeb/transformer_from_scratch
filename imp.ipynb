{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from beartype import beartype as typechecker\n",
    "import numpy as np\n",
    "from jaxtyping import UInt, Float, jaxtyped\n",
    "from torch import Tensor\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    torch.manual_seed(4)\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional embedding as defined by Vaswani et al., 2017.\n",
    "class PosEmbed(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=4, n_tokens=8, debug=False):\n",
    "        super().__init__()\n",
    "        self.debug = debug\n",
    "        self.d_model = d_model\n",
    "        self.n_tokens = n_tokens\n",
    "\n",
    "        posEmbedLst = []\n",
    "        for pos in range(n_tokens):\n",
    "            row = []\n",
    "            for dim in range(d_model):\n",
    "                if dim % 2 == 0:\n",
    "                    row += [self.sin(pos, dim)]\n",
    "                else:\n",
    "                    row += [self.cos(pos, dim)]\n",
    "            \n",
    "            posEmbedLst.append(row.copy())\n",
    "\n",
    "        self.posEmbed : Float[Tensor, \"n_tokens d_model\"] = nn.Parameter((\n",
    "            torch.tensor(posEmbedLst)\n",
    "        ))\n",
    "        if debug:\n",
    "            print(f\"{self.posEmbed=}\")\n",
    "\n",
    "    def sin(self, pos, evenDim):\n",
    "        return torch.sin(\n",
    "            torch.tensor(pos/self.n_tokens**(evenDim/self.d_model))\n",
    "        )\n",
    "    \n",
    "    def cos(self, pos, oddDim):\n",
    "        return torch.cos(\n",
    "            torch.tensor(pos/self.n_tokens**(oddDim/self.d_model))\n",
    "        )\n",
    "    \n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def forward(\n",
    "        self, input: Float[Tensor, \"*batch_size n_tokens d_model\"]\n",
    "    ) -> Float[Tensor, \"*batch_size n_tokens d_model\"]:\n",
    "        # I actually dont need and input!\n",
    "        r = input + self.posEmbed\n",
    "        if self.debug:\n",
    "            display(f\"{r=}\")\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 2.0000, 1.0000, 2.0000],\n",
       "        [1.8415, 1.8284, 1.3462, 1.9780],\n",
       "        [1.9093, 1.3724, 1.6496, 1.9129],\n",
       "        [1.1411, 0.7886, 1.8727, 1.8076],\n",
       "        [0.2432, 0.2774, 1.9878, 1.6668],\n",
       "        [0.0411, 0.0142, 1.9807, 1.4966],\n",
       "        [0.7206, 0.0894, 1.8523, 1.3045],\n",
       "        [1.6570, 0.4772, 1.6184, 1.0991]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((8, 4))\n",
    "PosEmbed().forward(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape: n_tokens x d_model\n",
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=4, n_tokens=8, n_head=2, debug=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_tokens = n_tokens\n",
    "        self.n_head = n_head\n",
    "        self.debug = debug\n",
    "\n",
    "        self.d_head = d_head = d_model // n_head\n",
    "        self.wQ: Float[Tensor, \"d_model d_head\"] = nn.Parameter(\n",
    "            torch.rand((d_model, d_head))\n",
    "        )\n",
    "        self.wK: Float[Tensor, \"d_model d_head\"] = nn.Parameter(\n",
    "            torch.rand((d_model, d_head))\n",
    "        )\n",
    "        self.wV: Float[Tensor, \"d_model d_head\"] = nn.Parameter(\n",
    "            torch.rand((d_model, d_head))\n",
    "        )\n",
    "\n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def forward(\n",
    "        self, input: Float[Tensor, \"*batch_size n_tokens d_model\"]\n",
    "    ) -> Float[Tensor, \"*batch_size n_tokens d_head\"]:\n",
    "        Q: Float[Tensor, \"*batch_size n_tokens d_head\"] = input @ self.wQ\n",
    "        K: Float[Tensor, \"*batch_size n_tokens d_head\"] = input @ self.wK\n",
    "        A: Float[Tensor, \"*batch_size n_tokens n_token\"] = (\n",
    "            Q @ K.transpose(dim0=-2, dim1=-1)\n",
    "        )\n",
    "        if self.debug:\n",
    "            display(A)\n",
    "        masked: Float[Tensor, \"*batch_size n_tokens n_tokens\"] = (\n",
    "            A + (torch.ones_like(A) * float(\"-inf\")).triu(diagonal=1)\n",
    "        )\n",
    "        if self.debug:\n",
    "            display(masked)\n",
    "        scores: Float[Tensor, \"*batch_size n_tokens n_token\"] = (\n",
    "            torch.softmax(masked / self.d_model**(1/2), dim=-1)\n",
    "        )\n",
    "        if self.debug:\n",
    "            display(scores)\n",
    "        V: Float[Tensor, \"*batch_size n_tokens d_head\"] = input @ self.wV\n",
    "        output: Float[Tensor, \"*batch_size n_tokens d_head\"] = scores @ V\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "a = torch.ones((1, 8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=4, n_tokens=8, mlp_factor=4, debug=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_tokens = n_tokens\n",
    "        self.mlp_factor = mlp_factor\n",
    "        self.debug = debug\n",
    "\n",
    "        self.encode: Float[Tensor, \"d_model d_model*mlp_factor\"] = nn.Parameter(\n",
    "            torch.rand((d_model, d_model*mlp_factor))\n",
    "        )\n",
    "        self.decode: Float[Tensor, \"d_model*mlp_factor d_model\"] = nn.Parameter(\n",
    "            torch.rand((d_model*mlp_factor, d_model))\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self, input: Float[Tensor, \"*batch_size n_tokens d_model\"]\n",
    "    ) -> Float[Tensor, \"*batch_size n_tokens d_model\"]:\n",
    "        output: Float[Tensor, \"*batch_size n_tokens d_model\"] = (\n",
    "            input @ self.encode @ self.decode \n",
    "        )\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.1447, 19.8279, 22.9614, 16.4457],\n",
       "        [15.1447, 19.8279, 22.9614, 16.4457],\n",
       "        [15.1447, 19.8279, 22.9614, 16.4457],\n",
       "        [15.1447, 19.8279, 22.9614, 16.4457],\n",
       "        [15.1447, 19.8279, 22.9614, 16.4457],\n",
       "        [15.1447, 19.8279, 22.9614, 16.4457],\n",
       "        [15.1447, 19.8279, 22.9614, 16.4457],\n",
       "        [15.1447, 19.8279, 22.9614, 16.4457]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "FeedForward().forward(torch.ones((8, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=4, n_tokens=8, debug=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_tokens = n_tokens\n",
    "        self.debug = debug\n",
    "\n",
    "    def forward(\n",
    "        self, input: Float[Tensor, \"*batch_size n_tokens d_model\"]\n",
    "    ) -> Float[Tensor, \"*batch_size n_tokens d_model\"]:\n",
    "        output = (\n",
    "            (input - input.mean(dim=-1, keepdim=True))\n",
    "            /input.std(dim=-1, keepdim=True)\n",
    "        )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.4901e-08,  0.0000e+00,  4.4703e-08,  6.7055e-08, -1.4901e-08,\n",
       "         -1.1176e-08,  1.0431e-07,  1.1176e-07]),\n",
       " tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "ln_ed = LayerNorm().forward(torch.rand((8, 4)))\n",
    "ln_ed.mean(-1), ln_ed.std(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=4, n_tokens=8, n_head=2, mlp_factor=4, debug=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_tokens = n_tokens\n",
    "        self.n_head = n_head\n",
    "        self.mlp_factor = mlp_factor\n",
    "        self.debug = debug\n",
    "\n",
    "        self.ln = LayerNorm(\n",
    "            d_model=self.d_model, n_tokens=self.n_tokens\n",
    "        )\n",
    "        self.heads = nn.ModuleList([\n",
    "            Head(\n",
    "                d_model=d_model, n_tokens=n_tokens, n_head=n_head, debug=debug\n",
    "            ) for _ in range(n_head)\n",
    "        ])\n",
    "        self.wO: Float[Tensor, \"d_model d_model\"] = nn.Parameter(torch.rand((\n",
    "            d_model, d_model                                                         \n",
    "        )))\n",
    "        self.ffw = FeedForward(\n",
    "            d_model=d_model, n_tokens=n_tokens,\n",
    "            mlp_factor=mlp_factor, debug=debug\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, input: Float[Tensor, \"*batch_size n_tokens d_model\"]\n",
    "    ) -> Float[Tensor, \"*batch_size n_tokens d_model\"]:\n",
    "        normInput = self.ln(input.clone())\n",
    "        outsLst: list[Float[Tensor, \"*batch_size n_token d_model/n_head\"]] = [\n",
    "            h(normInput.clone()).tolist() for h in self.heads\n",
    "        ]\n",
    "        outs: Float[Tensor, \"*batch_size n_head n_tokens d_model/n_head\"] = (\n",
    "            torch.tensor(outsLst)\n",
    "        )\n",
    "        outsTrans: Float[Tensor, \"*batch_size n_tokens n_head d_model/n_head\"] = (\n",
    "            outs.transpose(-3, -2).contiguous()\n",
    "        )\n",
    "        outsCat: Float[Tensor, \"*batch_size n_tokens d_model\"] = outsTrans.view(\n",
    "            tuple([*outsTrans.shape[:-2], self.d_model])\n",
    "        )\n",
    "        outsProj: Float[Tensor, \"*batch_size n_tokens d_model\"] = outsCat @ self.wO\n",
    "        outsSum: Float[Tensor, \"*batch_size n_tokens d_model\"] = outsProj + input.clone()\n",
    "        outsNorm: Float[Tensor, \"*batch_size n_tokens d_model\"] = self.ln(outsSum)\n",
    "        output: Float[Tensor, \"*batch_size n_tokens d_model\"] = self.ffw(outsNorm)\n",
    "        return output + input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wO',\n",
       " 'heads.0.wQ',\n",
       " 'heads.0.wK',\n",
       " 'heads.0.wV',\n",
       " 'heads.1.wQ',\n",
       " 'heads.1.wK',\n",
       " 'heads.1.wV',\n",
       " 'ffw.encode',\n",
       " 'ffw.decode']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "[name for name, _  in list(HiddenLayer().named_parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, num_layers=5, d_model=4, n_vocab=16,\n",
    "        n_tokens=8, n_head=2, mlp_factor=4, debug=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.n_vocab = n_vocab\n",
    "        self.n_tokens = n_tokens\n",
    "        self.n_head = n_head\n",
    "        self.mlp_factor = mlp_factor\n",
    "        self.debug = debug\n",
    "\n",
    "        self.embed: Float[Tensor, \"n_vocab d_model\"] = torch.rand(\n",
    "            (n_vocab, d_model)\n",
    "        )\n",
    "        self.posEmbed = PosEmbed(\n",
    "            d_model=d_model, n_tokens=n_tokens, debug=debug\n",
    "        )\n",
    "        self.hiddenLayers = nn.ModuleList([\n",
    "            HiddenLayer(\n",
    "                d_model=d_model, n_tokens=n_tokens, n_head=n_head,\n",
    "                mlp_factor=mlp_factor, debug=debug\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.unembed: Float[Tensor, \"d_model n_vocab\"] = torch.rand(\n",
    "            (d_model, n_vocab)\n",
    "        )\n",
    "        self.parameters += [\n",
    "            self.embed, self.hiddenLayers, self.unembed\n",
    "        ]\n",
    "    \n",
    "    def forward(\n",
    "        self, input: Float[Tensor, \"*batch_size n_tokens n_vocab\"]\n",
    "    ) -> Float[Tensor, \"*batch_size n_tokens n_vocab\"]:\n",
    "        emb: Float[Tensor, \"*batch_size n_tokens d_model\"] = self.posEmbed(\n",
    "            input @ self.embed\n",
    "        )\n",
    "        out = emb\n",
    "        for hl in self.hiddenLayers:\n",
    "            out = hl(out)\n",
    "        logits: Float[Tensor, \"*batch_size n_tokens n_vocab\"] = out @ self.unembed\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.8537e-01, -2.9655e-01, -4.0775e-01, -1.1655e+00, -8.5163e-01,\n",
       "          -1.8397e+00, -1.0331e+00, -1.0017e+00, -2.2193e+00, -4.9268e-01,\n",
       "          -1.9748e+00,  2.5402e-02, -8.8963e-01, -1.7210e+00, -1.4942e+00,\n",
       "          -4.2577e-01],\n",
       "         [ 1.1494e+00,  1.9409e+00,  8.3373e-01,  9.7188e-01,  6.4855e-01,\n",
       "           8.5670e-01,  6.6286e-01,  7.1370e-01,  1.2318e+00,  1.8213e+00,\n",
       "           2.9599e-01,  3.1077e+00,  6.3227e-01, -3.4496e-02,  1.2049e+00,\n",
       "           1.6290e+00],\n",
       "         [ 4.3700e+00,  6.9234e+00,  3.8467e+00,  5.0054e+00,  3.9598e+00,\n",
       "           7.0750e+00,  4.9282e+00,  5.1374e+00,  9.2090e+00,  7.6520e+00,\n",
       "           6.0487e+00,  9.9352e+00,  4.4578e+00,  4.6415e+00,  7.6291e+00,\n",
       "           6.4958e+00],\n",
       "         [ 1.3201e+01,  1.9243e+01,  1.2162e+01,  1.6287e+01,  1.1958e+01,\n",
       "           2.2672e+01,  1.5373e+01,  1.5418e+01,  2.8978e+01,  2.0808e+01,\n",
       "           2.0165e+01,  2.6545e+01,  1.3626e+01,  1.5247e+01,  2.3094e+01,\n",
       "           1.7414e+01],\n",
       "         [-2.9811e+00, -3.3347e+00, -2.2063e+00, -3.9746e+00, -2.5394e+00,\n",
       "          -4.8794e+00, -2.9495e+00, -2.8227e+00, -6.1122e+00, -3.2469e+00,\n",
       "          -4.2767e+00, -4.2907e+00, -2.5764e+00, -3.1013e+00, -4.5397e+00,\n",
       "          -2.8704e+00],\n",
       "         [ 9.4595e+00,  1.4257e+01,  9.0759e+00,  1.1785e+01,  9.0394e+00,\n",
       "           1.7252e+01,  1.1840e+01,  1.1991e+01,  2.2056e+01,  1.5946e+01,\n",
       "           1.5711e+01,  1.9574e+01,  1.0515e+01,  1.2237e+01,  1.7652e+01,\n",
       "           1.3223e+01],\n",
       "         [ 8.5810e+00,  1.2647e+01,  8.0612e+00,  1.0776e+01,  8.1712e+00,\n",
       "           1.5600e+01,  1.0600e+01,  1.0708e+01,  1.9911e+01,  1.4073e+01,\n",
       "           1.4194e+01,  1.7273e+01,  9.4077e+00,  1.1035e+01,  1.5844e+01,\n",
       "           1.1717e+01],\n",
       "         [ 1.6492e+00,  3.0606e+00,  1.4888e+00,  1.6443e+00,  1.4948e+00,\n",
       "           2.4684e+00,  1.8579e+00,  2.0408e+00,  3.3173e+00,  3.4857e+00,\n",
       "           1.9882e+00,  4.6126e+00,  1.7250e+00,  1.5591e+00,  2.9510e+00,\n",
       "           2.9596e+00]],\n",
       "\n",
       "        [[-3.5933e-01,  2.7080e-01,  2.7752e-01, -8.5299e-01, -6.6036e-01,\n",
       "          -1.2149e+00, -4.6478e-01, -5.1360e-01, -1.4549e+00,  1.1950e-01,\n",
       "          -1.2830e+00,  7.8009e-01, -4.3321e-01, -1.2546e+00, -8.7062e-01,\n",
       "          -7.6078e-02],\n",
       "         [-1.2671e+00, -9.1617e-01, -4.2780e-01, -1.8982e+00, -1.2861e+00,\n",
       "          -2.3394e+00, -1.1880e+00, -1.1998e+00, -2.9001e+00, -9.5658e-01,\n",
       "          -2.1212e+00, -9.2366e-01, -1.0693e+00, -1.7406e+00, -2.0144e+00,\n",
       "          -1.0229e+00],\n",
       "         [ 3.3963e+00,  5.4285e+00,  3.4010e+00,  3.8609e+00,  2.7850e+00,\n",
       "           5.2144e+00,  3.7461e+00,  3.7366e+00,  6.7485e+00,  5.6908e+00,\n",
       "           4.4078e+00,  7.8119e+00,  3.3177e+00,  3.1032e+00,  5.5838e+00,\n",
       "           4.6932e+00],\n",
       "         [ 4.8625e+00,  7.1144e+00,  4.8340e+00,  6.1502e+00,  4.4684e+00,\n",
       "           8.7547e+00,  5.9926e+00,  5.9270e+00,  1.1123e+01,  7.7227e+00,\n",
       "           7.9857e+00,  9.6699e+00,  5.2635e+00,  6.0423e+00,  8.7956e+00,\n",
       "           6.3332e+00],\n",
       "         [ 8.6064e+00,  1.2533e+01,  8.0564e+00,  1.0736e+01,  7.9157e+00,\n",
       "           1.5134e+01,  1.0266e+01,  1.0281e+01,  1.9307e+01,  1.3650e+01,\n",
       "           1.3609e+01,  1.7178e+01,  9.0844e+00,  1.0365e+01,  1.5338e+01,\n",
       "           1.1373e+01],\n",
       "         [ 6.6627e+00,  1.0302e+01,  6.7312e+00,  8.3359e+00,  6.4778e+00,\n",
       "           1.2516e+01,  8.7032e+00,  8.8021e+00,  1.5989e+01,  1.1650e+01,\n",
       "           1.1548e+01,  1.4119e+01,  7.7114e+00,  9.0455e+00,  1.2830e+01,\n",
       "           9.5501e+00],\n",
       "         [ 3.9893e+00,  6.7082e+00,  4.4973e+00,  4.9724e+00,  4.1019e+00,\n",
       "           8.0462e+00,  5.7908e+00,  5.9016e+00,  1.0301e+01,  7.8617e+00,\n",
       "           7.6200e+00,  9.2308e+00,  5.1309e+00,  6.1043e+00,  8.3831e+00,\n",
       "           6.3094e+00],\n",
       "         [ 7.2055e+00,  1.0953e+01,  6.5863e+00,  8.6244e+00,  6.5530e+00,\n",
       "           1.2152e+01,  8.3583e+00,  8.5191e+00,  1.5647e+01,  1.1992e+01,\n",
       "           1.0671e+01,  1.5376e+01,  7.4684e+00,  8.1304e+00,  1.2683e+01,\n",
       "           1.0076e+01]]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "Transformer().forward(torch.rand((8, 16)))\n",
    "Transformer().forward(torch.rand((2, 8, 16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "class TransformerTrainer():\n",
    "    \n",
    "    def __init__(self, model, optim_choice=Adam, epochs=1, lr=1e-7, debug=False):\n",
    "        self.model = model\n",
    "        self.optim_choice = optim_choice\n",
    "        self.epochs=epochs\n",
    "        self.lr=lr\n",
    "    \n",
    "    def getLoss(\n",
    "        self, batch: Float[Tensor, \"*batch_size n_tokens\"]\n",
    "    ):\n",
    "        inp = F.one_hot(\n",
    "            batch, num_classes=self.model.n_vocab\n",
    "        ).to(dtype=torch.float)\n",
    "        logits: Float[Tensor, \"*batch_size n_tokens n_vocab\"] = self.model(inp)\n",
    "        probs = logits.softmax(-1)\n",
    "        correctProbs : Float[Tensor, \"*batch_size n_tokens-1\"] = (\n",
    "            probs[:-1][..., range(probs.shape[-2] - 1), labels[1:]]\n",
    "        )\n",
    "        loss: Float[Tensor, \"*batch_size n_tokens-1\"] = (\n",
    "            correctProbs.log().neg()\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "    def train(\n",
    "        self, batches: list[Float[Tensor, \"*batch_size n_tokens\"]]\n",
    "    ):\n",
    "        optimizer = self.optim_choice(self.model.parameters(), lr=self.lr) \n",
    "        for bath in batches:\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.get_loss(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6346, 0.0803]), tensor([-0.4548, -2.5219]))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((2))\n",
    "a, a.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8, 10,  9, 12, 12,  6, 14]),\n",
       " torch.Size([8, 16]),\n",
       " torch.Size([8, 16]),\n",
       " tensor([0.0620, 0.0263, 0.0490, 0.0066, 0.0124, 0.0199, 0.0300]),\n",
       " tensor([2.7811, 3.6381, 3.0168, 5.0167, 4.3897, 3.9162, 3.5056]))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "debugModel = Transformer()\n",
    "labels = torch.randint(0, 16, (8, ))\n",
    "inp = F.one_hot(labels, num_classes=16).to(dtype=torch.float)\n",
    "logits = debugModel(inp)\n",
    "probs = logits.softmax(-1)\n",
    "correctLogits = probs[:-1][..., range(probs.shape[-2] - 1), labels[1:]]\n",
    "loss = correctLogits.log().neg()\n",
    "labels[1:], inp.shape, probs.shape, correctLogits, loss\n",
    "# torch.tensor([[1, 2], [3, 4]])[..., torch.tensor([1, 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debugModel = Transformer()\n",
    "debugBatch = [torch.randint(0, 16, (8,)) for _ in range(5)]\n",
    "# TransformerTrainer(debugModel).train(debugBatch)\n",
    "debugModel.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
